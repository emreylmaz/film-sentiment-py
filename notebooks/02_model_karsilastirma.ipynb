{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IMDB Sentiment Analizi - Model Karşılaştırma\n",
        "\n",
        "**Proje:** IMDB Film Yorumları Sentiment Analizi  \n",
        "**Tarih:** 5 Kasım 2025  \n",
        "**Amaç:** Model eğitimi ve performans karşılaştırması\n",
        "\n",
        "---\n",
        "\n",
        "## İçindekiler\n",
        "\n",
        "1. Veri Hazırlama\n",
        "2. Ön İşleme\n",
        "3. Model Eğitimi\n",
        "4. Model Değerlendirme\n",
        "5. Model Karşılaştırma\n",
        "6. Sonuçlar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import kütüphaneleri\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import yaml\n",
        "\n",
        "# Proje modüllerimiz\n",
        "from src.data_loader import load_data, split_data\n",
        "from src.preprocessor import TextPreprocessor\n",
        "from src.train_model import SentimentModelTrainer\n",
        "from src.evaluate_model import ModelEvaluator\n",
        "\n",
        "# Ayarlar\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)\n",
        "\n",
        "print(\"✓ Kütüphaneler yüklendi\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Veri Hazırlama\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config yükle\n",
        "with open('../config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Veriyi yükle\n",
        "df = load_data(config['data']['raw_path'])\n",
        "print(f\"Dataset boyutu: {df.shape}\")\n",
        "\n",
        "# Train-test split\n",
        "train_df, test_df = split_data(\n",
        "    df, \n",
        "    test_size=config['data']['test_size'],\n",
        "    random_state=config['data']['random_state']\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_df)} örnekler\")\n",
        "print(f\"Test: {len(test_df)} örnekler\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Eğitimi\n",
        "\n",
        "**Not:** Model eğitimi `python src/train_model.py` komutu ile yapılabilir.  \n",
        "Bu notebook, eğitim sonrası sonuçları analiz etmek içindir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model eğitimi (opsiyonel - çok uzun sürebilir)\n",
        "# trainer = SentimentModelTrainer()\n",
        "# results = trainer.train_all_models()\n",
        "\n",
        "# Veya eğitilmiş modeli yükle\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# Model ve metadata yükle\n",
        "try:\n",
        "    with open('../models/model.pkl', 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    \n",
        "    with open('../models/metadata.json', 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "    \n",
        "    print(\"✓ Model yüklendi\")\n",
        "    print(f\"Model tipi: {metadata['model_type']}\")\n",
        "    print(f\"Eğitim tarihi: {metadata['training_date']}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠ Model bulunamadı. Lütfen önce 'python src/train_model.py' çalıştırın.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
